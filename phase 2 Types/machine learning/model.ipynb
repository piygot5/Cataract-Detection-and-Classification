{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import imutils\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.feature import  greycomatrix, greycoprops\n",
    "import re\n",
    "from tabulate import tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import confusion_matrix  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from skimage.measure import shannon_entropy\n",
    "import time\n",
    "import threading\n",
    "rf_class = RandomForestClassifier(n_estimators=100)\n",
    "abc = AdaBoostClassifier(n_estimators=100,learning_rate=1)\n",
    "xgb = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=500,\n",
    " max_depth=10,\n",
    " min_child_weight=1,\n",
    " gamma=0.1,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " nthread=4,\n",
    " seed=27)\n",
    "svm_linear=svm.SVC(kernel='linear',gamma=0.001,C=100)\n",
    "model_names={\"Random Forest\":rf_class,\"AdaBoostClassifier\":abc,\"XGBClassifier\":xgb,\"SVM_linear\":svm_linear}\n",
    "class_names=['mild','normal','severe']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model:    \n",
    "    def __init__(self,dataset,**kwargs):\n",
    "        size = None\n",
    "        if len(kwargs.items())!=0:\n",
    "           size = kwargs['size']\n",
    "        self.dataset = dataset\n",
    "        self.SIFT, self.GLCM, self.SIFT_AND_GLCM,self.labels = self.generateFeatureDataset(self.dataset,size)\n",
    "    \n",
    "    def generateFeatureDataset(self,dataset,size):\n",
    "        t =time.time()\n",
    "        subdirs = [x[0] for x in os.walk(dataset)]\n",
    "        file_names=[]\n",
    "        for sub_dir in subdirs[1:4]:\n",
    "            mypath = sub_dir\n",
    "            sub_folder_file_names = [mypath+\"/\"+f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "            file_names += sub_folder_file_names\n",
    "        min_dim = []\n",
    "        images_sift = []\n",
    "        glcm=[]\n",
    "        labels = []\n",
    "        size = size\n",
    "        sift = cv2.xfeatures2d.SIFT_create()\n",
    "        for i, file in enumerate(file_names):\n",
    "            image = cv2.imread(file,0)\n",
    "            if size is not None:\n",
    "                image = cv2.resize(image, (size, size), interpolation = cv2.INTER_AREA)\n",
    "            glcm.append(self.glcm2D(image))\n",
    "            descriptors = self.sift2D(image,sift)\n",
    "            images_sift.append(descriptors)\n",
    "            min_dim.append(len(descriptors))\n",
    "            if re.split(r'[`[\\]\\'\\\\/]', file_names[i])[-2]=='mild':\n",
    "                labels.append(0)\n",
    "            elif re.split(r'[`[\\]\\'\\\\/]', file_names[i])[-2] == 'normal':\n",
    "                labels.append(1)\n",
    "            else :\n",
    "                labels.append(2)\n",
    "\n",
    "        images_sift_final = [features[:min(min_dim)] for features in images_sift]\n",
    "        images_sift_final =np.array(images_sift_final)\n",
    "        glcm=np.array(glcm)\n",
    "        images_sift_glcm=np.concatenate((images_sift_final,glcm),axis=1)\n",
    "        print(time.time()-t)\n",
    "        return images_sift_final,glcm,images_sift_glcm,labels\n",
    "    \n",
    "    def sift2D(self,image,sift):\n",
    "        keypoints, descriptors = sift.detectAndCompute(image,None)\n",
    "        descriptors=np.array(descriptors)      \n",
    "        descriptors=descriptors.reshape(-1)\n",
    "        return descriptors\n",
    "    def glcm2D(self,image):\n",
    "        img_arr = np.array(image)\n",
    "        gCoMat = greycomatrix(img_arr, [1], [0],256,symmetric=True, normed=True) # Co-occurance matrix\n",
    "        contrast = greycoprops(gCoMat, prop='contrast')[0][0]\n",
    "        dissimilarity = greycoprops(gCoMat, prop='dissimilarity')[0][0]\n",
    "        homogeneity = greycoprops(gCoMat, prop='homogeneity')[0][0]\n",
    "        energy = greycoprops(gCoMat, prop='energy')[0][0]\n",
    "        correlation = greycoprops(gCoMat, prop='correlation')[0][0]\n",
    "        entropy = shannon_entropy(img_arr)\n",
    "        return [contrast,dissimilarity,homogeneity,energy,correlation,entropy]\n",
    "        \n",
    "    \n",
    "    def accuracy(self,model_name,X_train, X_test, y_train, y_test):\n",
    "        model=model_names[model_name]\n",
    "        model.fit(X_train,y_train)\n",
    "        yhat = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, yhat)\n",
    "        acc = str(round(acc, 2)*100) + ' %'\n",
    "        return [model_name,acc]\n",
    "    \n",
    "    def classification_report(self,model_name,X_train, X_test, y_train, y_test):\n",
    "        model=model_names[model_name]\n",
    "        model.fit(X_train,y_train)\n",
    "        yhat = model.predict(X_test)\n",
    "        print(classification_report(y_test, yhat, target_names=class_names))\n",
    "        print(confusion_matrix(y_test, yhat))\n",
    "        acc = accuracy_score(y_test, yhat)\n",
    "        acc = str(round(acc, 2)*100) + ' %'\n",
    "        return [model_name,acc]\n",
    "    \n",
    "    \n",
    "    def result(self,dataset,metrics,model_used = [\"Random Forest\",\"AdaBoostClassifier\",\"XGBClassifier\",\"SVM_linear\"]):\n",
    "        min_max_scaler = preprocessing.StandardScaler()\n",
    "        x_scaled = min_max_scaler.fit_transform(dataset)\n",
    "        df=pd.DataFrame(data=x_scaled)\n",
    "        df['label']=self.labels\n",
    "        df=df.sample(frac=1)\n",
    "        X=df.drop(['label'], axis = 1)\n",
    "        y=df['label']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "        model_result = []       \n",
    "        for model in model_used:\n",
    "            model_result.append(getattr(self, metrics)(model,X_train, X_test, y_train, y_test))\n",
    "        print(tabulate(model_result, headers=['Model', 'Result'], tablefmt='orgtbl'))\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    def run(self,**kwargs):\n",
    "        metrics ='accuracy'\n",
    "        dataset_use = ['SIFT','GLCM','SIFT_AND_GLCM']\n",
    "        if 'metrics' in kwargs.keys():\n",
    "            metrics = kwargs['metrics']\n",
    "        if 'dataset_use' in kwargs.keys():\n",
    "            dataset_use = kwargs['dataset_use']\n",
    "        for dataset in dataset_use:\n",
    "            print(\"\\n\")\n",
    "            print('\\t----{0}----'.format(dataset))\n",
    "            print(\"\\n\")\n",
    "            return self.result(getattr(self, dataset),metrics)\n",
    "            print(\"---------------------------------------------------------------------------------------\")\n",
    "\n",
    "              \n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************Running 224 preprocessed images******************\n",
      "5.586017608642578\n",
      "\n",
      "\n",
      "\t----SIFT_AND_GLCM----\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        mild       0.79      0.90      0.84        50\n",
      "      normal       0.71      0.67      0.69        30\n",
      "      severe       0.88      0.73      0.80        30\n",
      "\n",
      "    accuracy                           0.79       110\n",
      "   macro avg       0.79      0.77      0.78       110\n",
      "weighted avg       0.79      0.79      0.79       110\n",
      "\n",
      "[[45  5  0]\n",
      " [ 7 20  3]\n",
      " [ 5  3 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        mild       0.84      0.94      0.89        50\n",
      "      normal       0.82      0.77      0.79        30\n",
      "      severe       0.92      0.80      0.86        30\n",
      "\n",
      "    accuracy                           0.85       110\n",
      "   macro avg       0.86      0.84      0.85       110\n",
      "weighted avg       0.86      0.85      0.85       110\n",
      "\n",
      "[[47  3  0]\n",
      " [ 5 23  2]\n",
      " [ 4  2 24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        mild       0.91      0.96      0.93        50\n",
      "      normal       0.90      0.87      0.88        30\n",
      "      severe       0.93      0.87      0.90        30\n",
      "\n",
      "    accuracy                           0.91       110\n",
      "   macro avg       0.91      0.90      0.90       110\n",
      "weighted avg       0.91      0.91      0.91       110\n",
      "\n",
      "[[48  2  0]\n",
      " [ 2 26  2]\n",
      " [ 3  1 26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        mild       0.74      0.74      0.74        50\n",
      "      normal       0.51      0.60      0.55        30\n",
      "      severe       0.80      0.67      0.73        30\n",
      "\n",
      "    accuracy                           0.68       110\n",
      "   macro avg       0.68      0.67      0.67       110\n",
      "weighted avg       0.69      0.68      0.69       110\n",
      "\n",
      "[[37 10  3]\n",
      " [10 18  2]\n",
      " [ 3  7 20]]\n",
      "| Model              | Result   |\n",
      "|--------------------+----------|\n",
      "| Random Forest      | 79.0 %   |\n",
      "| AdaBoostClassifier | 85.0 %   |\n",
      "| XGBClassifier      | 91.0 %   |\n",
      "| SVM_linear         | 68.0 %   |\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"***************Running 224 preprocessed images******************\")\n",
    "\n",
    "model_224=model('../Deep learning/preprocessed images_224',size=128)\n",
    "model_224.run(metrics='classification_report',dataset_use=['SIFT_AND_GLCM'])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"***************Running 224 preprocessed images******************\")\n",
    "\n",
    "model_224=model('../Deep learning/preprocessed images_224',size=128)\n",
    "model_224.run(metrics='classification_report',dataset_use=['GLCM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"***************Running 40 preprocessed images******************\")\n",
    "\n",
    "model_40=model('../Deep learning/preprocessed_images_40',size=128)\n",
    "model_40.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************Running original preprocessed images******************\n",
      "\n",
      "\n",
      "\t---SIFT---\n",
      "| Model              | Result   |\n",
      "|--------------------+----------|\n",
      "| Random Forest      | 45.0%    |\n",
      "| AdaBoostClassifier | 47.0%    |\n",
      "| XGBClassifier      | 51.0%    |\n",
      "\n",
      "\n",
      "\t---Glcm---\n",
      "| Model              | Result   |\n",
      "|--------------------+----------|\n",
      "| Random Forest      | 83.0%    |\n",
      "| AdaBoostClassifier | 66.0%    |\n",
      "| XGBClassifier      | 82.0%    |\n",
      "\n",
      "\n",
      "\t---SIFT + GLCM---\n",
      "| Model              | Result             |\n",
      "|--------------------+--------------------|\n",
      "| Random Forest      | 66.0%              |\n",
      "| AdaBoostClassifier | 56.99999999999999% |\n",
      "| XGBClassifier      | 84.0%              |\n"
     ]
    }
   ],
   "source": [
    "print(\"***************Running original preprocessed images******************\")\n",
    "\n",
    "model_1000=model('../Deep learning/preprocessed images')\n",
    "model_1000.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************Running original Dataset images******************\n",
      "\n",
      "\n",
      "\t---SIFT---\n",
      "| Model              | Result   |\n",
      "|--------------------+----------|\n",
      "| Random Forest      | 39.0%    |\n",
      "| AdaBoostClassifier | 43.0%    |\n",
      "| XGBClassifier      | 45.0%    |\n",
      "\n",
      "\n",
      "\t---Glcm---\n",
      "| Model              | Result   |\n",
      "|--------------------+----------|\n",
      "| Random Forest      | 95.0%    |\n",
      "| AdaBoostClassifier | 63.0%    |\n",
      "| XGBClassifier      | 93.0%    |\n",
      "\n",
      "\n",
      "\t---SIFT + GLCM---\n",
      "| Model              | Result   |\n",
      "|--------------------+----------|\n",
      "| Random Forest      | 52.0%    |\n",
      "| AdaBoostClassifier | 76.0%    |\n",
      "| XGBClassifier      | 95.0%    |\n"
     ]
    }
   ],
   "source": [
    "print(\"***************Running original Dataset images******************\")\n",
    "\n",
    "model_org=model('../Deep learning/Dataset')\n",
    "model_org.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# import pandas as pd\n",
    "# target_df = pd.get_dummies(labels,prefix=\"label\")\n",
    "# target_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
